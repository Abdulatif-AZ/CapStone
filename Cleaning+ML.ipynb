{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1972ffa3",
   "metadata": {},
   "source": [
    "Data Cleaning + Prepration and ML Modling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d3cfd5",
   "metadata": {},
   "source": [
    "# 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eea9352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04ef1c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9df9b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89684ac",
   "metadata": {},
   "source": [
    "# 2. Loading the Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e8dd8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "r_df = pd.read_csv('real_instances.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50618488",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618c0775",
   "metadata": {},
   "source": [
    "## 2. Pre-processing real_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aca840af",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = r_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0e0ad7",
   "metadata": {},
   "source": [
    "#### 2.1.  Drop features with >85^% of meissing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5444534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features with high missing data (> 85%) based on EDA\n",
    "features_to_drop = ['P-JUS-BS', 'P-JUS-CKP', 'P-MON-CKGL', 'T-MON-CKP', 'P-MON-SDV-P', 'PT-P', 'QBS']\n",
    "\n",
    "temp_df.drop(columns=features_to_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111eafbc",
   "metadata": {},
   "source": [
    "#### 2.2.  Drop instances messing classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c702f6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after dropping missing labels: 28843850\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where the 'class' column has missing (NaN) values\n",
    "temp_df = temp_df.dropna(subset=['class'])\n",
    "\n",
    "# Check the number of rows remaining after dropping\n",
    "print(f\"Number of rows after dropping missing labels: {temp_df.shape[0]}\")\n",
    "\n",
    "# Check if there are any remaining missing values in 'class'\n",
    "print(temp_df['class'].isnull().sum())  # Should print 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa54c8e",
   "metadata": {},
   "source": [
    "#### 2.3.  Impute rest of missing features using mean across same class type and well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d702a085",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ma123\\AppData\\Local\\Temp\\ipykernel_22600\\1349884788.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df.groupby(['well', 'class'])[column].transform(lambda x: x.fillna(x.mean()))\n",
      "C:\\Users\\ma123\\AppData\\Local\\Temp\\ipykernel_22600\\1349884788.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df.groupby(['well', 'class'])[column].transform(lambda x: x.fillna(x.mean()))\n",
      "C:\\Users\\ma123\\AppData\\Local\\Temp\\ipykernel_22600\\1349884788.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df.groupby(['well', 'class'])[column].transform(lambda x: x.fillna(x.mean()))\n",
      "C:\\Users\\ma123\\AppData\\Local\\Temp\\ipykernel_22600\\1349884788.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df.groupby(['well', 'class'])[column].transform(lambda x: x.fillna(x.mean()))\n",
      "C:\\Users\\ma123\\AppData\\Local\\Temp\\ipykernel_22600\\1349884788.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df.groupby(['well', 'class'])[column].transform(lambda x: x.fillna(x.mean()))\n",
      "C:\\Users\\ma123\\AppData\\Local\\Temp\\ipykernel_22600\\1349884788.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df.groupby(['well', 'class'])[column].transform(lambda x: x.fillna(x.mean()))\n",
      "C:\\Users\\ma123\\AppData\\Local\\Temp\\ipykernel_22600\\1349884788.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df.groupby(['well', 'class'])[column].transform(lambda x: x.fillna(x.mean()))\n",
      "C:\\Users\\ma123\\AppData\\Local\\Temp\\ipykernel_22600\\1349884788.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df.groupby(['well', 'class'])[column].transform(lambda x: x.fillna(x.mean()))\n",
      "C:\\Users\\ma123\\AppData\\Local\\Temp\\ipykernel_22600\\1349884788.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df.groupby(['well', 'class'])[column].transform(lambda x: x.fillna(x.mean()))\n",
      "C:\\Users\\ma123\\AppData\\Local\\Temp\\ipykernel_22600\\1349884788.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df.groupby(['well', 'class'])[column].transform(lambda x: x.fillna(x.mean()))\n",
      "C:\\Users\\ma123\\AppData\\Local\\Temp\\ipykernel_22600\\1349884788.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df.groupby(['well', 'class'])[column].transform(lambda x: x.fillna(x.mean()))\n",
      "C:\\Users\\ma123\\AppData\\Local\\Temp\\ipykernel_22600\\1349884788.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df.groupby(['well', 'class'])[column].transform(lambda x: x.fillna(x.mean()))\n",
      "C:\\Users\\ma123\\AppData\\Local\\Temp\\ipykernel_22600\\1349884788.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df.groupby(['well', 'class'])[column].transform(lambda x: x.fillna(x.mean()))\n",
      "C:\\Users\\ma123\\AppData\\Local\\Temp\\ipykernel_22600\\1349884788.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df.groupby(['well', 'class'])[column].transform(lambda x: x.fillna(x.mean()))\n",
      "C:\\Users\\ma123\\AppData\\Local\\Temp\\ipykernel_22600\\1349884788.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df.groupby(['well', 'class'])[column].transform(lambda x: x.fillna(x.mean()))\n",
      "C:\\Users\\ma123\\AppData\\Local\\Temp\\ipykernel_22600\\1349884788.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df.groupby(['well', 'class'])[column].transform(lambda x: x.fillna(x.mean()))\n",
      "C:\\Users\\ma123\\AppData\\Local\\Temp\\ipykernel_22600\\1349884788.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df.groupby(['well', 'class'])[column].transform(lambda x: x.fillna(x.mean()))\n",
      "C:\\Users\\ma123\\AppData\\Local\\Temp\\ipykernel_22600\\1349884788.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df.groupby(['well', 'class'])[column].transform(lambda x: x.fillna(x.mean()))\n",
      "C:\\Users\\ma123\\AppData\\Local\\Temp\\ipykernel_22600\\1349884788.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df.groupby(['well', 'class'])[column].transform(lambda x: x.fillna(x.mean()))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ma123\\AppData\\Local\\Temp\\ipykernel_22600\\1349884788.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df.groupby(['well', 'class'])[column].transform(lambda x: x.fillna(x.mean()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp               0\n",
      "label                   0\n",
      "well                    0\n",
      "id                      0\n",
      "ABER-CKGL        21379029\n",
      "ABER-CKP         17588881\n",
      "ESTADO-DHSV      16668218\n",
      "ESTADO-M1        12782303\n",
      "ESTADO-M2        12806080\n",
      "ESTADO-PXO       12580613\n",
      "ESTADO-SDV-GL    13400572\n",
      "ESTADO-SDV-P      6614910\n",
      "ESTADO-W1        11910304\n",
      "ESTADO-W2        12307438\n",
      "ESTADO-XO        12221682\n",
      "P-ANULAR          6534177\n",
      "P-JUS-CKGL        6268383\n",
      "P-MON-CKP         5644192\n",
      "P-PDG             6244642\n",
      "P-TPT             4795839\n",
      "QGL              12716265\n",
      "T-JUS-CKP        14022372\n",
      "T-PDG             8918366\n",
      "T-TPT             3585222\n",
      "class                   0\n",
      "state                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Function to impute missing values with the mean of the same class and well\n",
    "def impute_class_well_mean(df):\n",
    "    # Get a list of columns with missing values\n",
    "    columns_with_missing_values = df.columns[df.isnull().any()].tolist()\n",
    "    \n",
    "    for column in columns_with_missing_values:\n",
    "        # Group by both class and well, and fill missing values with the group-wise mean\n",
    "        df[column] = df.groupby(['well', 'class'])[column].transform(lambda x: x.fillna(x.mean()))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Impute missing values in all columns with missing values\n",
    "temp_df = impute_class_well_mean(temp_df)\n",
    "\n",
    "# Check if missing values are filled\n",
    "print(temp_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1389408",
   "metadata": {},
   "source": [
    "### 2.1.  Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9c93050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ma123\\AppData\\Local\\Temp\\ipykernel_22600\\3400152519.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df['class'] = temp_df['class'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "temp_df['class'] = temp_df['class'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bcec18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2884385, 26)\n",
      "0      0.505139\n",
      "107    0.231265\n",
      "108    0.126731\n",
      "4      0.085109\n",
      "3      0.019732\n",
      "105    0.011117\n",
      "109    0.006776\n",
      "8      0.004886\n",
      "102    0.003089\n",
      "101    0.002265\n",
      "7      0.001052\n",
      "2      0.000738\n",
      "9      0.000615\n",
      "6      0.000461\n",
      "5      0.000458\n",
      "1      0.000339\n",
      "106    0.000228\n",
      "Name: class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Stratified sampling to maintain class proportions (ensuring all labels are present)\n",
    "r_df_sample, _ = train_test_split(temp_df, test_size=0.90, stratify=temp_df['class'], random_state=42)\n",
    "\n",
    "# Check the size and distribution of the sample\n",
    "print(r_df_sample.shape)\n",
    "print(r_df_sample['class'].value_counts(normalize=True))  # Check class proportions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef91ebd3",
   "metadata": {},
   "source": [
    "## 3 ML Classifcation Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cacd1d",
   "metadata": {},
   "source": [
    "### 3.1 Expriment 1: XGBoost Classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00a68f1",
   "metadata": {},
   "source": [
    "Model Loading & Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "871fa2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Assuming 'r_df_sample' is your dataset and 'class' is the target variable\n",
    "# X will be the features, y will be the target class\n",
    "X = r_df_sample.drop(columns=['class'])  # Features (drop the class column)\n",
    "y = r_df_sample['class']  # Target (the class labels)\n",
    "\n",
    "# Split the data into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5e2f56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform y for both training and test sets\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Check the transformed class labels\n",
    "print(np.unique(y_train))  # Ensure they are integers starting from 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ef779a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class labels to integers if needed\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1e466d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set columns after dropping: Index(['ABER-CKGL', 'ABER-CKP', 'ESTADO-DHSV', 'ESTADO-M1', 'ESTADO-M2',\n",
      "       'ESTADO-PXO', 'ESTADO-SDV-GL', 'ESTADO-SDV-P', 'ESTADO-W1', 'ESTADO-W2',\n",
      "       'ESTADO-XO', 'P-ANULAR', 'P-JUS-CKGL', 'P-MON-CKP', 'P-PDG', 'P-TPT',\n",
      "       'QGL', 'T-JUS-CKP', 'T-PDG', 'T-TPT', 'state'],\n",
      "      dtype='object')\n",
      "Test set columns after dropping: Index(['ABER-CKGL', 'ABER-CKP', 'ESTADO-DHSV', 'ESTADO-M1', 'ESTADO-M2',\n",
      "       'ESTADO-PXO', 'ESTADO-SDV-GL', 'ESTADO-SDV-P', 'ESTADO-W1', 'ESTADO-W2',\n",
      "       'ESTADO-XO', 'P-ANULAR', 'P-JUS-CKGL', 'P-MON-CKP', 'P-PDG', 'P-TPT',\n",
      "       'QGL', 'T-JUS-CKP', 'T-PDG', 'T-TPT', 'state'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Columns to drop from the dataset\n",
    "columns_to_drop = ['timestamp', 'label', 'well', 'id']\n",
    "\n",
    "# Drop these columns from both the training and test sets\n",
    "X_train = X_train.drop(columns=columns_to_drop)\n",
    "X_test = X_test.drop(columns=columns_to_drop)\n",
    "\n",
    "# Verify that the columns have been dropped\n",
    "print(\"Training set columns after dropping:\", X_train.columns)\n",
    "print(\"Test set columns after dropping:\", X_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60ef135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and test data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95682170",
   "metadata": {},
   "source": [
    "Model Training & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17ceca15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 98.63%\n"
     ]
    }
   ],
   "source": [
    "# Initialize XGBoost classifier for multi-class classification\n",
    "xgb_simple_model = XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)), random_state=42)\n",
    "\n",
    "# Train the model on the scaled data\n",
    "xgb_simple_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = xgb_simple_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfa02ad",
   "metadata": {},
   "source": [
    "Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7316db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that class 0.0 is excluded before transforming\n",
    "subset_df = temp_df.sample(frac=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc78b25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy on 10% of the data excluding class 0: 98.57%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Exclude rows where class is 0\n",
    "subset_df = subset_df[subset_df['class'] != 0]  # Exclude class 0\n",
    "\n",
    "# Separate features and target\n",
    "X_subset = subset_df.drop(columns=columns_to_drop + ['class'])  # Drop unwanted columns\n",
    "y_subset = subset_df['class']  # Target (class labels)\n",
    "\n",
    "# 1. Label encode the target variable using the original label encoder\n",
    "# Ensure that the original label encoder includes class 0 in its classes\n",
    "y_subset_encoded = label_encoder.transform(y_subset)  # Use the original label_encoder (fitted on the full dataset)\n",
    "\n",
    "# 2. Convert all feature columns to integer values\n",
    "#X_subset = X_subset.astype(int)\n",
    "\n",
    "# 3. Apply the same StandardScaler used in the original model\n",
    "X_subset_scaled = scaler.transform(X_subset)\n",
    "\n",
    "# 4. Use the previously trained model to make predictions\n",
    "y_subset_pred = xgb_simple_model.predict(X_subset_scaled)\n",
    "\n",
    "\n",
    "# 6. Calculate accuracy on the 10% subset\n",
    "accuracy_subset = accuracy_score(y_subset_encoded, y_subset_pred)\n",
    "print(f\"Prediction Accuracy on 10% of the data excluding class 0: {accuracy_subset * 100:.2f}%\")\n",
    "\n",
    "# 7. (Optional) Print the classification report\n",
    "#print(classification_report(y_subset_encoded, y_subset_pred, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893eaaae",
   "metadata": {},
   "source": [
    "Run the model on the eniter real dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd6a902b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy on the full real data excluding class 0: 98.57%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Exclude rows where class is 0\n",
    "new_df = temp_df[temp_df['class'] != 0]  # Exclude class 0\n",
    "\n",
    "# Separate features and target\n",
    "X_subset = new_df.drop(columns=columns_to_drop + ['class'])  # Drop unwanted columns\n",
    "y_subset = new_df['class']  # Target (class labels)\n",
    "\n",
    "# 1. Label encode the target variable using the original label encoder\n",
    "# Ensure that the original label encoder includes class 0 in its classes\n",
    "y_subset_encoded = label_encoder.transform(y_subset)  # Use the original label_encoder (fitted on the full dataset)\n",
    "\n",
    "# 2. Convert all feature columns to integer values\n",
    "#X_subset = X_subset.astype(int)\n",
    "\n",
    "# 3. Apply the same StandardScaler used in the original model\n",
    "X_subset_scaled = scaler.transform(X_subset)\n",
    "\n",
    "# 4. Use the previously trained model to make predictions\n",
    "y_subset_pred = xgb_simple_model.predict(X_subset_scaled)\n",
    "\n",
    "\n",
    "# 6. Calculate accuracy on the 10% subset\n",
    "accuracy_subset = accuracy_score(y_subset_encoded, y_subset_pred)\n",
    "print(f\"Prediction Accuracy on the full real data excluding class 0: {accuracy_subset * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d5be9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ma123\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 98.57%\n",
      "Precision: 99.89%\n",
      "Recall: 98.57%\n",
      "F1 Score: 99.22%\n",
      "Confusion Matrix:\n",
      "[[      0       0       0       0       0       0       0       0       0\n",
      "        0       0       0       0       0       0       0       0]\n",
      " [      0    9576       0       0       0       0       0       0       0\n",
      "        0     207       0       0       0       0       0       0]\n",
      " [      0       0   21190       0       0       0       0       0       0\n",
      "        0       0      84       0       0       0       0       0]\n",
      " [      0       0       0  568555     597       0       0       0       0\n",
      "        0       0       0       0       0       0       0       0]\n",
      " [  29728       0       0     223 2424924       0       0       0       0\n",
      "        0       8       0       0       0       0       0       0]\n",
      " [      0       0       0       0       0   13017       0       0       0\n",
      "        0       0       0     188       0       0       0       0]\n",
      " [    847       0       0       0       0       0   12166       0       0\n",
      "        0       0       0       0     272       0       0       0]\n",
      " [      0       0       0       0       0       0       0   26373       0\n",
      "        0       0       0       0       0    3966       0       0]\n",
      " [      0       0       0       0       0       0       0       0  138810\n",
      "        0       0       0       0       0       0    2110       0]\n",
      " [      0       0       0       0       0       0       0       0       0\n",
      "    17653       0       0       0       0       0       0      99]\n",
      " [    706     545       0       0       0       0       0       0       0\n",
      "        0   64089       0       0       0       0       0       0]\n",
      " [   1130       0    1942       0       0       0       0       0       0\n",
      "        0       0   86019       0       0       0       0       0]\n",
      " [   1495       0       0       0       0     421       0       0       0\n",
      "        0       0       0  318756       0       0       0       0]\n",
      " [   3791       0       0       0       0       0     767       0       0\n",
      "        0       0       0       0    2011       0       0       0]\n",
      " [  61325       0       0       0       0       0       0    1722       0\n",
      "        0       0       0       0       0 6607535       0       0]\n",
      " [  86573       0       0       0       0       0       0       0    2021\n",
      "        0       0       0       0       0       0 3566824       0]\n",
      " [   3464       0       0       0       0       0       0       0       0\n",
      "        5       0       0       0       0       0       0  191974]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "accuracy_subset = accuracy_score(y_subset_encoded, y_subset_pred)\n",
    "\n",
    "# Calculate precision, recall, F1-score\n",
    "precision_subset = precision_score(y_subset_encoded, y_subset_pred, average='weighted')  # Weighted for imbalanced classes\n",
    "recall_subset = recall_score(y_subset_encoded, y_subset_pred, average='weighted')\n",
    "f1_subset = f1_score(y_subset_encoded, y_subset_pred, average='weighted')\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_subset_encoded, y_subset_pred)\n",
    "\n",
    "# Print out all the metrics\n",
    "print(f\"Prediction Accuracy: {accuracy_subset * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_subset * 100:.2f}%\")\n",
    "print(f\"Recall: {recall_subset * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1_subset * 100:.2f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c36060f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy per Well:\n",
      "well\n",
      "WELL-00001    0.844772\n",
      "WELL-00002    0.946624\n",
      "WELL-00003    0.202475\n",
      "WELL-00004    0.992004\n",
      "WELL-00005    0.999967\n",
      "WELL-00006    0.091996\n",
      "WELL-00007    1.000000\n",
      "WELL-00009    0.347326\n",
      "WELL-00010    0.996246\n",
      "WELL-00011    0.190024\n",
      "WELL-00012    0.144197\n",
      "WELL-00013    0.111972\n",
      "WELL-00014    0.910328\n",
      "WELL-00015    0.067168\n",
      "WELL-00016    0.396990\n",
      "WELL-00019    0.054227\n",
      "WELL-00020    0.014563\n",
      "WELL-00021    0.000000\n",
      "WELL-00022    0.000000\n",
      "WELL-00023    0.000000\n",
      "WELL-00024    0.001088\n",
      "WELL-00025    0.059840\n",
      "WELL-00026    0.004065\n",
      "WELL-00027    0.045898\n",
      "WELL-00028    0.020104\n",
      "WELL-00029    0.046979\n",
      "WELL-00030    0.066617\n",
      "WELL-00031    0.008436\n",
      "WELL-00032    0.091350\n",
      "WELL-00037    0.000000\n",
      "WELL-00040    0.000000\n",
      "WELL-00041    0.000000\n",
      "WELL-00042    0.159961\n",
      "dtype: float64\n",
      "Accuracy per Class:\n",
      "class\n",
      "1      0.978841\n",
      "2      0.996052\n",
      "3      0.998951\n",
      "4      0.987796\n",
      "5      0.985763\n",
      "6      0.915770\n",
      "7      0.869277\n",
      "8      0.985027\n",
      "9      0.994423\n",
      "101    0.000000\n",
      "102    0.000000\n",
      "105    0.000000\n",
      "106    0.000000\n",
      "107    0.000000\n",
      "108    0.000000\n",
      "109    0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Ensure y_subset_pred and y_subset_encoded are available (predicted and actual labels)\n",
    "\n",
    "# Add 'class' and 'well' information back to the predictions\n",
    "results_df = new_df.copy()  # Use your DataFrame with class and well columns\n",
    "results_df['predicted_class'] = y_subset_pred  # Add predicted labels to the DataFrame\n",
    "\n",
    "# 1. Accuracy per well\n",
    "well_accuracy = results_df.groupby('well').apply(\n",
    "    lambda x: accuracy_score(x['class'], x['predicted_class'])\n",
    ")\n",
    "\n",
    "print(\"Accuracy per Well:\")\n",
    "print(well_accuracy)\n",
    "\n",
    "# 2. Accuracy per class\n",
    "class_accuracy = results_df.groupby('class').apply(\n",
    "    lambda x: accuracy_score(x['class'], x['predicted_class'])\n",
    ")\n",
    "\n",
    "print(\"Accuracy per Class:\")\n",
    "print(class_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d18e248",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ma123\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ma123\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.98      0.96      9783\n",
      "           2       0.92      1.00      0.95     21274\n",
      "           3       1.00      1.00      1.00    569152\n",
      "           4       1.00      0.99      0.99   2454883\n",
      "           5       0.97      0.99      0.98     13205\n",
      "           6       0.94      0.92      0.93     13285\n",
      "           7       0.94      0.87      0.90     30339\n",
      "           8       0.99      0.99      0.99    140920\n",
      "           9       1.00      0.99      1.00     17752\n",
      "          10       1.00      0.98      0.99     65340\n",
      "          11       1.00      0.97      0.98     89091\n",
      "          12       1.00      0.99      1.00    320672\n",
      "          13       0.88      0.31      0.45      6569\n",
      "          14       1.00      0.99      0.99   6670582\n",
      "          15       1.00      0.98      0.99   3655418\n",
      "          16       1.00      0.98      0.99    195443\n",
      "\n",
      "    accuracy                           0.99  14273708\n",
      "   macro avg       0.92      0.88      0.89  14273708\n",
      "weighted avg       1.00      0.99      0.99  14273708\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ma123\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Print the classification report for each class\n",
    "print(classification_report(y_subset_encoded, y_subset_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c25df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
