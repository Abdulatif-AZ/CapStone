{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1972ffa3",
   "metadata": {},
   "source": [
    "In this notebook we will perfrom two step predection  1st by identfy normal or abnormal then another round of predection the exact event type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d3cfd5",
   "metadata": {},
   "source": [
    "# 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eea9352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04ef1c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9df9b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89684ac",
   "metadata": {},
   "source": [
    "# 2. Loading the Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0fa83a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = pd.read_csv('real_normal.csv')\n",
    "abnormal = pd.read_csv('real_abnormal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8014228",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_df = normal\n",
    "abnormal_df = abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "544750be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Feature    Normal  Abnomral\n",
      "0       timestamp         0         0\n",
      "1           label         0         0\n",
      "2            well         0         0\n",
      "3              id         0         0\n",
      "4       ABER-CKGL  10736697  13644040\n",
      "5        ABER-CKP  10593466   9952326\n",
      "6     ESTADO-DHSV   6307285  12699568\n",
      "7       ESTADO-M1   6164054   8934991\n",
      "8       ESTADO-M2   6164054   9019914\n",
      "9      ESTADO-PXO   5606911   9089136\n",
      "10  ESTADO-SDV-GL   7563940   8203039\n",
      "11   ESTADO-SDV-P   5736080   2820063\n",
      "12      ESTADO-W1   6164054   7770160\n",
      "13      ESTADO-W2   5607326   8971462\n",
      "14      ESTADO-XO   5606911   8726609\n",
      "15       P-ANULAR   1382513   6029222\n",
      "16       P-JUS-BS  12158183  20714067\n",
      "17     P-JUS-CKGL   5079440   2742431\n",
      "18      P-JUS-CKP  12014952  17408397\n",
      "19     P-MON-CKGL  12158183  20405341\n",
      "20      P-MON-CKP   5607366   1472485\n",
      "21    P-MON-SDV-P  12158183  20714067\n",
      "22          P-PDG   2488921   5427295\n",
      "23           PT-P  12158183  20714067\n",
      "24          P-TPT   1217710   4164073\n",
      "25            QBS  12158183  20714067\n",
      "26            QGL   7007212   8144933\n",
      "27      T-JUS-CKP   6307255   9725645\n",
      "28      T-MON-CKP  12014952  15906752\n",
      "29          T-PDG   7435235   4625743\n",
      "30          T-TPT   1217723   3239527\n",
      "31          class   2138400   1890000\n",
      "32          state   2138400   1890000\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of missing values in each dataset\n",
    "normal_df_missing = normal_df.isnull().sum().to_frame('Normal')\n",
    "abnormal_df_missing = abnormal_df.isnull().sum().to_frame('Abnomral')\n",
    "\n",
    "# Combine the missing values data\n",
    "missing_values = normal_df_missing.join(abnormal_df_missing, how='outer')\n",
    "\n",
    "# Reset index to have 'Feature' column\n",
    "missing_values = missing_values.rename_axis('Feature').reset_index()\n",
    "\n",
    "# Display the missing values comparison\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5ec049",
   "metadata": {},
   "source": [
    "### 3.4.1 Missing Values %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adaa37e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Feature      Normal    Abnormal\n",
      "0       timestamp    0.000000    0.000000\n",
      "1           label    0.000000    0.000000\n",
      "2            well    0.000000    0.000000\n",
      "3              id    0.000000    0.000000\n",
      "4       ABER-CKGL   88.308401   65.868475\n",
      "5        ABER-CKP   87.130338   48.046219\n",
      "6     ESTADO-DHSV   51.876872   61.308907\n",
      "7       ESTADO-M1   50.698809   43.134895\n",
      "8       ESTADO-M2   50.698809   43.544872\n",
      "9      ESTADO-PXO   46.116356   43.879051\n",
      "10  ESTADO-SDV-GL   62.212750   39.601296\n",
      "11   ESTADO-SDV-P   47.178760   13.614241\n",
      "12      ESTADO-W1   50.698809   37.511513\n",
      "13      ESTADO-W2   46.119770   43.310964\n",
      "14      ESTADO-XO   46.116356   42.128902\n",
      "15       P-ANULAR   11.371049   29.106896\n",
      "16       P-JUS-BS  100.000000  100.000000\n",
      "17     P-JUS-CKGL   41.777953   13.239462\n",
      "18      P-JUS-CKP   98.821937   84.041425\n",
      "19     P-MON-CKGL  100.000000   98.509583\n",
      "20      P-MON-CKP   46.120099    7.108623\n",
      "21    P-MON-SDV-P  100.000000  100.000000\n",
      "22          P-PDG   20.471159   26.201011\n",
      "23           PT-P  100.000000  100.000000\n",
      "24          P-TPT   10.015559   20.102634\n",
      "25            QBS  100.000000  100.000000\n",
      "26            QGL   57.633711   39.320781\n",
      "27      T-JUS-CKP   51.876625   46.951885\n",
      "28      T-MON-CKP   98.821937   76.792027\n",
      "29          T-PDG   61.154163   22.331409\n",
      "30          T-TPT   10.015666   15.639261\n",
      "31          class   17.588154    9.124234\n",
      "32          state   17.588154    9.124234\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate missing value percentages\n",
    "def missing_percentage(df, dataset_name):\n",
    "    total = df.shape[0]\n",
    "    missing_count = df.isnull().sum()\n",
    "    missing_percent = (missing_count / total) * 100\n",
    "    return missing_percent.to_frame(dataset_name)\n",
    "\n",
    "# Calculate missing percentages for each dataset\n",
    "normal_df_missing = missing_percentage(normal_df, 'Normal')\n",
    "abnormal_df_missing = missing_percentage(abnormal_df, 'Abnormal')\n",
    "\n",
    "# Combine the percentages\n",
    "missing_percentages = normal_df_missing.join(abnormal_df_missing)\n",
    "missing_percentages = missing_percentages.rename_axis('Feature').reset_index()\n",
    "\n",
    "# Display the missing percentages\n",
    "print(missing_percentages)\n",
    "\n",
    "#features_to_drop = ['P-JUS-BS', 'P-JUS-CKP', 'P-MON-CKGL', 'T-MON-CKP', 'P-MON-SDV-P', 'PT-P', 'QBS', 'ABER-CKGL', ' ABER-CKP']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618c0775",
   "metadata": {},
   "source": [
    "## 2. Pre-processing real_instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0e0ad7",
   "metadata": {},
   "source": [
    "#### 2.1.  Drop features with >75^% of meissing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5444534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features with high missing data (> 85%)\n",
    "features_to_drop = ['P-JUS-BS', 'P-JUS-CKP', 'P-MON-CKGL', 'T-MON-CKP', 'P-MON-SDV-P', 'PT-P', 'QBS', 'ABER-CKGL', 'ABER-CKP']\n",
    "\n",
    "normal.drop(columns=features_to_drop, inplace=True)\n",
    "abnormal.drop(columns=features_to_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa54c8e",
   "metadata": {},
   "source": [
    "#### 2.3.  Impute rest of missing features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d702a085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp        0\n",
      "label            0\n",
      "well             0\n",
      "id               0\n",
      "ESTADO-DHSV      0\n",
      "ESTADO-M1        0\n",
      "ESTADO-M2        0\n",
      "ESTADO-PXO       0\n",
      "ESTADO-SDV-GL    0\n",
      "ESTADO-SDV-P     0\n",
      "ESTADO-W1        0\n",
      "ESTADO-W2        0\n",
      "ESTADO-XO        0\n",
      "P-ANULAR         0\n",
      "P-JUS-CKGL       0\n",
      "P-MON-CKP        0\n",
      "P-PDG            0\n",
      "P-TPT            0\n",
      "QGL              0\n",
      "T-JUS-CKP        0\n",
      "T-PDG            0\n",
      "T-TPT            0\n",
      "class            0\n",
      "state            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Function to impute missing values using forward and backward filling within each 'class' and 'well' group\n",
    "def impute_class_well_fill(df):\n",
    "    # Identify columns that contain missing values\n",
    "    columns_with_missing_values = df.columns[df.isnull().any()].tolist()\n",
    "    \n",
    "    # Iterate over each column with missing values\n",
    "    for column in columns_with_missing_values:\n",
    "        # Group by both 'class' and 'well' and apply forward fill, then backward fill\n",
    "        df[column] = df.groupby(['label'])[column].transform(lambda x: x.ffill().bfill())\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Impute missing values in all columns with missing values\n",
    "x_normal = impute_class_well_fill(normal)\n",
    "\n",
    "# Check if missing values are filled\n",
    "print(x_normal.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d41219f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp              0\n",
      "label                  0\n",
      "well                   0\n",
      "id                     0\n",
      "ESTADO-DHSV            0\n",
      "ESTADO-M1              0\n",
      "ESTADO-M2              0\n",
      "ESTADO-PXO             0\n",
      "ESTADO-SDV-GL      77477\n",
      "ESTADO-SDV-P           0\n",
      "ESTADO-W1              0\n",
      "ESTADO-W2              0\n",
      "ESTADO-XO              0\n",
      "P-ANULAR               0\n",
      "P-JUS-CKGL         77477\n",
      "P-MON-CKP              0\n",
      "P-PDG                  0\n",
      "P-TPT                  0\n",
      "QGL                77477\n",
      "T-JUS-CKP        4809035\n",
      "T-PDG                  0\n",
      "T-TPT                  0\n",
      "class                  0\n",
      "state                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Impute missing values in all columns with missing values\n",
    "x_abnormal = impute_class_well_fill(abnormal)\n",
    "\n",
    "# Check if missing values are filled\n",
    "print(x_abnormal.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8abdf31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'ESTADO-SDV-GL' has 77477 missing values.\n",
      "Associated Classes: [6]\n",
      "Associated Wells: ['WELL-00004' 'WELL-00002']\n",
      "----------------------------------------\n",
      "Column 'P-JUS-CKGL' has 77477 missing values.\n",
      "Associated Classes: [6]\n",
      "Associated Wells: ['WELL-00004' 'WELL-00002']\n",
      "----------------------------------------\n",
      "Column 'QGL' has 77477 missing values.\n",
      "Associated Classes: [6]\n",
      "Associated Wells: ['WELL-00004' 'WELL-00002']\n",
      "----------------------------------------\n",
      "Column 'T-JUS-CKP' has 4809035 missing values.\n",
      "Associated Classes: [8]\n",
      "Associated Wells: ['WELL-00026' 'WELL-00019' 'WELL-00030' 'WELL-00027' 'WELL-00029'\n",
      " 'WELL-00031' 'WELL-00032' 'WELL-00028' 'WELL-00025']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "missing_info = {}\n",
    "\n",
    "# Columns with remaining missing values after filling\n",
    "columns_with_missing = ['ESTADO-SDV-GL', 'P-JUS-CKGL', 'QGL', 'T-JUS-CKP']\n",
    "\n",
    "# Loop through each column with missing values to check associated 'class' and 'well'\n",
    "for column in columns_with_missing:\n",
    "    # Get the rows where the column still has missing values\n",
    "    missing_rows = x_abnormal[x_abnormal[column].isna()]\n",
    "    # Get the unique classes and wells associated with missing values in this column\n",
    "    missing_info[column] = {\n",
    "        'label': missing_rows['label'].unique(),\n",
    "        'well': missing_rows['well'].unique(),\n",
    "        'count': missing_rows.shape[0]\n",
    "    }\n",
    "\n",
    "# Display the results\n",
    "for column, info in missing_info.items():\n",
    "    print(f\"Column '{column}' has {info['count']} missing values.\")\n",
    "    print(f\"Associated Classes: {info['label']}\")\n",
    "    print(f\"Associated Wells: {info['well']}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "022bc977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of wells to delete with label 6\n",
    "wells_to_delete = ['WELL-00026', 'WELL-00019', 'WELL-00030', 'WELL-00027', \n",
    "                   'WELL-00029', 'WELL-00031', 'WELL-00032', 'WELL-00028', 'WELL-00025']\n",
    "\n",
    "# Filter out rows where label is 6 and well is in the specified list\n",
    "x_abnormal = x_abnormal[~((x_abnormal['label'] == 6) | (x_abnormal['well'].isin(wells_to_delete)))]\n",
    "x_normal = x_normal[~((x_normal['label'] == 6) | (x_normal['well'].isin(wells_to_delete)))]\n",
    "\n",
    "# Display the DataFrame to confirm the rows have been deleted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e69da4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp        0\n",
      "label            0\n",
      "well             0\n",
      "id               0\n",
      "ESTADO-DHSV      0\n",
      "ESTADO-M1        0\n",
      "ESTADO-M2        0\n",
      "ESTADO-PXO       0\n",
      "ESTADO-SDV-GL    0\n",
      "ESTADO-SDV-P     0\n",
      "ESTADO-W1        0\n",
      "ESTADO-W2        0\n",
      "ESTADO-XO        0\n",
      "P-ANULAR         0\n",
      "P-JUS-CKGL       0\n",
      "P-MON-CKP        0\n",
      "P-PDG            0\n",
      "P-TPT            0\n",
      "QGL              0\n",
      "T-JUS-CKP        0\n",
      "T-PDG            0\n",
      "T-TPT            0\n",
      "class            0\n",
      "state            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(x_abnormal.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "717e223d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ma123\\AppData\\Local\\Temp\\ipykernel_18816\\1904061805.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_abnormal['is_normal'] = 0\n",
      "C:\\Users\\ma123\\AppData\\Local\\Temp\\ipykernel_18816\\1904061805.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_normal['is_normal'] = 1\n"
     ]
    }
   ],
   "source": [
    "x_abnormal['is_normal'] = 0\n",
    "x_normal['is_normal'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29a927d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "      <th>well</th>\n",
       "      <th>id</th>\n",
       "      <th>ESTADO-DHSV</th>\n",
       "      <th>ESTADO-M1</th>\n",
       "      <th>ESTADO-M2</th>\n",
       "      <th>ESTADO-PXO</th>\n",
       "      <th>ESTADO-SDV-GL</th>\n",
       "      <th>ESTADO-SDV-P</th>\n",
       "      <th>...</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>QGL</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>T-PDG</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>class</th>\n",
       "      <th>state</th>\n",
       "      <th>is_normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-12-17 14:27:45</td>\n",
       "      <td>9</td>\n",
       "      <td>WELL-00042</td>\n",
       "      <td>20141217142745</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2190777.0</td>\n",
       "      <td>18979920.0</td>\n",
       "      <td>10180070.0</td>\n",
       "      <td>3.032789</td>\n",
       "      <td>40.20570</td>\n",
       "      <td>74.58371</td>\n",
       "      <td>58.95389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-12-17 14:27:46</td>\n",
       "      <td>9</td>\n",
       "      <td>WELL-00042</td>\n",
       "      <td>20141217142745</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2190779.0</td>\n",
       "      <td>18979930.0</td>\n",
       "      <td>10180060.0</td>\n",
       "      <td>3.033681</td>\n",
       "      <td>40.20566</td>\n",
       "      <td>74.58370</td>\n",
       "      <td>58.95395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-12-17 14:27:47</td>\n",
       "      <td>9</td>\n",
       "      <td>WELL-00042</td>\n",
       "      <td>20141217142745</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2190780.0</td>\n",
       "      <td>18979940.0</td>\n",
       "      <td>10180050.0</td>\n",
       "      <td>3.034572</td>\n",
       "      <td>40.20562</td>\n",
       "      <td>74.58369</td>\n",
       "      <td>58.95401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-12-17 14:27:48</td>\n",
       "      <td>9</td>\n",
       "      <td>WELL-00042</td>\n",
       "      <td>20141217142745</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2190781.0</td>\n",
       "      <td>18979950.0</td>\n",
       "      <td>10180040.0</td>\n",
       "      <td>3.035463</td>\n",
       "      <td>40.20559</td>\n",
       "      <td>74.58368</td>\n",
       "      <td>58.95407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-12-17 14:27:49</td>\n",
       "      <td>9</td>\n",
       "      <td>WELL-00042</td>\n",
       "      <td>20141217142745</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2190782.0</td>\n",
       "      <td>18979960.0</td>\n",
       "      <td>10180040.0</td>\n",
       "      <td>3.036354</td>\n",
       "      <td>40.20555</td>\n",
       "      <td>74.58368</td>\n",
       "      <td>58.95413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20714062</th>\n",
       "      <td>2014-03-20 04:20:34</td>\n",
       "      <td>5</td>\n",
       "      <td>WELL-00020</td>\n",
       "      <td>20140319110000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1311047.0</td>\n",
       "      <td>32308910.0</td>\n",
       "      <td>4631294.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.23388</td>\n",
       "      <td>118.15850</td>\n",
       "      <td>87.30427</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20714063</th>\n",
       "      <td>2014-03-20 04:20:35</td>\n",
       "      <td>5</td>\n",
       "      <td>WELL-00020</td>\n",
       "      <td>20140319110000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1310748.0</td>\n",
       "      <td>32308910.0</td>\n",
       "      <td>4630961.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.23269</td>\n",
       "      <td>118.15850</td>\n",
       "      <td>87.30622</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20714064</th>\n",
       "      <td>2014-03-20 04:20:36</td>\n",
       "      <td>5</td>\n",
       "      <td>WELL-00020</td>\n",
       "      <td>20140319110000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1310449.0</td>\n",
       "      <td>32308910.0</td>\n",
       "      <td>4630629.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.23150</td>\n",
       "      <td>118.15850</td>\n",
       "      <td>87.30817</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20714065</th>\n",
       "      <td>2014-03-20 04:20:37</td>\n",
       "      <td>5</td>\n",
       "      <td>WELL-00020</td>\n",
       "      <td>20140319110000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1310150.0</td>\n",
       "      <td>32308910.0</td>\n",
       "      <td>4630296.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.23031</td>\n",
       "      <td>118.15850</td>\n",
       "      <td>87.31013</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20714066</th>\n",
       "      <td>2014-03-20 04:20:38</td>\n",
       "      <td>5</td>\n",
       "      <td>WELL-00020</td>\n",
       "      <td>20140319110000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1309851.0</td>\n",
       "      <td>32308910.0</td>\n",
       "      <td>4629964.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.22912</td>\n",
       "      <td>118.15850</td>\n",
       "      <td>87.31208</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15827555 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    timestamp  label        well              id  ESTADO-DHSV  \\\n",
       "0         2014-12-17 14:27:45      9  WELL-00042  20141217142745          1.0   \n",
       "1         2014-12-17 14:27:46      9  WELL-00042  20141217142745          1.0   \n",
       "2         2014-12-17 14:27:47      9  WELL-00042  20141217142745          1.0   \n",
       "3         2014-12-17 14:27:48      9  WELL-00042  20141217142745          1.0   \n",
       "4         2014-12-17 14:27:49      9  WELL-00042  20141217142745          1.0   \n",
       "...                       ...    ...         ...             ...          ...   \n",
       "20714062  2014-03-20 04:20:34      5  WELL-00020  20140319110000          1.0   \n",
       "20714063  2014-03-20 04:20:35      5  WELL-00020  20140319110000          1.0   \n",
       "20714064  2014-03-20 04:20:36      5  WELL-00020  20140319110000          1.0   \n",
       "20714065  2014-03-20 04:20:37      5  WELL-00020  20140319110000          1.0   \n",
       "20714066  2014-03-20 04:20:38      5  WELL-00020  20140319110000          1.0   \n",
       "\n",
       "          ESTADO-M1  ESTADO-M2  ESTADO-PXO  ESTADO-SDV-GL  ESTADO-SDV-P  ...  \\\n",
       "0               1.0        1.0         0.0            1.0           1.0  ...   \n",
       "1               1.0        1.0         0.0            1.0           1.0  ...   \n",
       "2               1.0        1.0         0.0            1.0           1.0  ...   \n",
       "3               1.0        1.0         0.0            1.0           1.0  ...   \n",
       "4               1.0        1.0         0.0            1.0           1.0  ...   \n",
       "...             ...        ...         ...            ...           ...  ...   \n",
       "20714062        1.0        0.0         0.0            0.0           1.0  ...   \n",
       "20714063        1.0        0.0         0.0            0.0           1.0  ...   \n",
       "20714064        1.0        0.0         0.0            0.0           1.0  ...   \n",
       "20714065        1.0        0.0         0.0            0.0           1.0  ...   \n",
       "20714066        1.0        0.0         0.0            0.0           1.0  ...   \n",
       "\n",
       "          P-MON-CKP       P-PDG       P-TPT       QGL  T-JUS-CKP      T-PDG  \\\n",
       "0         2190777.0  18979920.0  10180070.0  3.032789   40.20570   74.58371   \n",
       "1         2190779.0  18979930.0  10180060.0  3.033681   40.20566   74.58370   \n",
       "2         2190780.0  18979940.0  10180050.0  3.034572   40.20562   74.58369   \n",
       "3         2190781.0  18979950.0  10180040.0  3.035463   40.20559   74.58368   \n",
       "4         2190782.0  18979960.0  10180040.0  3.036354   40.20555   74.58368   \n",
       "...             ...         ...         ...       ...        ...        ...   \n",
       "20714062  1311047.0  32308910.0   4631294.0  0.000000   31.23388  118.15850   \n",
       "20714063  1310748.0  32308910.0   4630961.0  0.000000   31.23269  118.15850   \n",
       "20714064  1310449.0  32308910.0   4630629.0  0.000000   31.23150  118.15850   \n",
       "20714065  1310150.0  32308910.0   4630296.0  0.000000   31.23031  118.15850   \n",
       "20714066  1309851.0  32308910.0   4629964.0  0.000000   31.22912  118.15850   \n",
       "\n",
       "             T-TPT  class  state  is_normal  \n",
       "0         58.95389    0.0    0.0          0  \n",
       "1         58.95395    0.0    0.0          0  \n",
       "2         58.95401    0.0    0.0          0  \n",
       "3         58.95407    0.0    0.0          0  \n",
       "4         58.95413    0.0    0.0          0  \n",
       "...            ...    ...    ...        ...  \n",
       "20714062  87.30427    5.0    0.0          0  \n",
       "20714063  87.30622    5.0    0.0          0  \n",
       "20714064  87.30817    5.0    0.0          0  \n",
       "20714065  87.31013    5.0    0.0          0  \n",
       "20714066  87.31208    5.0    0.0          0  \n",
       "\n",
       "[15827555 rows x 25 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_abnormal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1389408",
   "metadata": {},
   "source": [
    "### 2.1.  resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bcec18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_normal_sample, _ = train_test_split(x_normal, test_size=0.80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63ff1a0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15827555, 25)\n",
      "7    0.496915\n",
      "4    0.233118\n",
      "9    0.166505\n",
      "3    0.043238\n",
      "5    0.027762\n",
      "2    0.017501\n",
      "1    0.014961\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(x_abnormal.shape)\n",
    "\n",
    "print(x_abnormal['label'].value_counts(normalize=True))  # Check class proportions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac3b15c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: Counter({7: 7864945, 4: 3689683, 9: 2635372, 3: 684352, 5: 439408, 2: 277001, 1: 236794})\n",
      "Resampled class distribution: Counter({7: 7864945, 1: 7864945, 4: 3689683, 9: 2635372, 3: 684352, 5: 439408, 2: 277001})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Separate features and labels\n",
    "X = x_abnormal.select_dtypes(include=[float, int])  # Keep only numeric columns\n",
    "y = x_abnormal['label']  # Define the label column\n",
    "\n",
    "# Initialize SMOTE for oversampling only minority classes\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "\n",
    "# Apply SMOTE to create a balanced dataset\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Check the distribution of classes after applying SMOTE\n",
    "print(\"Original class distribution:\", Counter(y))\n",
    "print(\"Resampled class distribution:\", Counter(y_resampled))\n",
    "\n",
    "# Combine resampled features and labels back into a DataFrame if needed\n",
    "x_abnormal_resampled = X_resampled.copy()\n",
    "x_abnormal_resampled['label'] = y_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d000106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23455706, 23)\n",
      "7    0.335311\n",
      "1    0.335311\n",
      "4    0.157304\n",
      "9    0.112355\n",
      "3    0.029176\n",
      "5    0.018734\n",
      "2    0.011810\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(x_abnormal_resampled.shape)\n",
    "\n",
    "print(x_abnormal_resampled['label'].value_counts(normalize=True))  # Check class proportions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96fdbfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([x_normal_sample, x_abnormal_resampled], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7121758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25858696, 25)\n",
      "7    0.304151\n",
      "1    0.304151\n",
      "4    0.142686\n",
      "9    0.101914\n",
      "0    0.092928\n",
      "3    0.026465\n",
      "5    0.016993\n",
      "2    0.010712\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.shape)\n",
    "\n",
    "print(merged_df['label'].value_counts(normalize=True))  # Check class proportions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef91ebd3",
   "metadata": {},
   "source": [
    "## 3 ML Classifcation Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cacd1d",
   "metadata": {},
   "source": [
    "### 3.1 Expriment 1: XGBoost Classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00a68f1",
   "metadata": {},
   "source": [
    "Model Loading & Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "871fa2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Assuming 'r_df_sample' is your dataset and 'class' is the target variable\n",
    "# X will be the features, y will be the target class\n",
    "X = merged_df.drop(columns=['is_normal'])  # Features (drop the class column)\n",
    "y = merged_df['is_normal']  # Target (the class labels)\n",
    "\n",
    "# Split the data into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5e2f56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform y for both training and test sets\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Check the transformed class labels\n",
    "print(np.unique(y_train))  # Ensure they are integers starting from 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ef779a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class labels to integers if needed\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1e466d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set columns after dropping: Index(['ESTADO-DHSV', 'ESTADO-M1', 'ESTADO-M2', 'ESTADO-PXO', 'ESTADO-SDV-GL',\n",
      "       'ESTADO-SDV-P', 'ESTADO-W1', 'ESTADO-W2', 'ESTADO-XO', 'P-ANULAR',\n",
      "       'P-JUS-CKGL', 'P-MON-CKP', 'P-PDG', 'P-TPT', 'QGL', 'T-JUS-CKP',\n",
      "       'T-PDG', 'T-TPT'],\n",
      "      dtype='object')\n",
      "Test set columns after dropping: Index(['ESTADO-DHSV', 'ESTADO-M1', 'ESTADO-M2', 'ESTADO-PXO', 'ESTADO-SDV-GL',\n",
      "       'ESTADO-SDV-P', 'ESTADO-W1', 'ESTADO-W2', 'ESTADO-XO', 'P-ANULAR',\n",
      "       'P-JUS-CKGL', 'P-MON-CKP', 'P-PDG', 'P-TPT', 'QGL', 'T-JUS-CKP',\n",
      "       'T-PDG', 'T-TPT'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Columns to drop from the dataset\n",
    "columns_to_drop = ['timestamp', 'class', 'well', 'id','state','label']\n",
    "\n",
    "# Drop these columns from both the training and test sets\n",
    "X_train = X_train.drop(columns=columns_to_drop)\n",
    "X_test = X_test.drop(columns=columns_to_drop)\n",
    "\n",
    "# Verify that the columns have been dropped\n",
    "print(\"Training set columns after dropping:\", X_train.columns)\n",
    "print(\"Test set columns after dropping:\", X_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60ef135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and test data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95682170",
   "metadata": {},
   "source": [
    "Model Training & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b11168de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 97.42%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize Logistic Regression model for binary classification\n",
    "logistic_model = LogisticRegression(solver='saga', max_iter=1000,random_state=42)\n",
    "\n",
    "# Train the model on the scaled data\n",
    "logistic_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = logistic_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "217800b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# X will be the features, y will be the target class\n",
    "X = x_abnormal_resampled.drop(columns=['label'])  # Features (drop the class column)\n",
    "y = x_abnormal_resampled['label']  # Target (the class labels)\n",
    "\n",
    "# Split the data into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "\n",
    "# Fit and transform y for both training and test sets\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Check the transformed class labels\n",
    "print(np.unique(y_train))  # Ensure they are integers starting from 0\n",
    "\n",
    "\n",
    "# Convert class labels to integers if needed\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d8c1917",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set columns after dropping: Index(['ESTADO-DHSV', 'ESTADO-M1', 'ESTADO-M2', 'ESTADO-PXO', 'ESTADO-SDV-GL',\n",
      "       'ESTADO-SDV-P', 'ESTADO-W1', 'ESTADO-W2', 'ESTADO-XO', 'P-ANULAR',\n",
      "       'P-JUS-CKGL', 'P-MON-CKP', 'P-PDG', 'P-TPT', 'QGL', 'T-JUS-CKP',\n",
      "       'T-PDG', 'T-TPT'],\n",
      "      dtype='object')\n",
      "Test set columns after dropping: Index(['ESTADO-DHSV', 'ESTADO-M1', 'ESTADO-M2', 'ESTADO-PXO', 'ESTADO-SDV-GL',\n",
      "       'ESTADO-SDV-P', 'ESTADO-W1', 'ESTADO-W2', 'ESTADO-XO', 'P-ANULAR',\n",
      "       'P-JUS-CKGL', 'P-MON-CKP', 'P-PDG', 'P-TPT', 'QGL', 'T-JUS-CKP',\n",
      "       'T-PDG', 'T-TPT'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Columns to drop from the dataset\n",
    "columns_to_drop = [ 'class', 'id','state','is_normal']\n",
    "\n",
    "# Drop these columns from both the training and test sets\n",
    "X_train = X_train.drop(columns=columns_to_drop)\n",
    "X_test = X_test.drop(columns=columns_to_drop)\n",
    "\n",
    "# Verify that the columns have been dropped\n",
    "print(\"Training set columns after dropping:\", X_train.columns)\n",
    "print(\"Test set columns after dropping:\", X_test.columns)\n",
    "\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and test data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00743dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 99.98%\n"
     ]
    }
   ],
   "source": [
    "# Initialize XGBoost classifier for multi-class classification\n",
    "xgb_simple_model = XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)), random_state=42)\n",
    "\n",
    "# Train the model on the scaled data\n",
    "xgb_simple_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = xgb_simple_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
