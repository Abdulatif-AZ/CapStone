{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/real_instances.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_real \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData/real_instances.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m df_sim \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData/simulated_instances.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m df_drawn \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData/hand_drawn_instances.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/real_instances.csv'"
     ]
    }
   ],
   "source": [
    "df_real = pd.read_csv('Data/real_instances.csv')\n",
    "df_sim = pd.read_csv('Data/simulated_instances.csv')\n",
    "df_drawn = pd.read_csv('Data/hand_drawn_instances.csv')\n",
    "\n",
    "#combine all dataframes\n",
    "df = pd.concat([df_real, df_sim, df_drawn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of null values in the cleaned dataframe\n",
      "timestamp          0.000000\n",
      "label              0.000000\n",
      "well               0.000000\n",
      "id                 0.000000\n",
      "ABER-CKGL         88.912638\n",
      "ABER-CKP          83.905354\n",
      "ESTADO-DHSV       81.895962\n",
      "ESTADO-M1         76.793540\n",
      "ESTADO-M2         76.904424\n",
      "ESTADO-PXO        76.267346\n",
      "ESTADO-SDV-GL     77.665661\n",
      "ESTADO-SDV-P      68.250478\n",
      "ESTADO-W1         75.272622\n",
      "ESTADO-W2         76.114241\n",
      "ESTADO-XO         75.793995\n",
      "P-ANULAR          66.756226\n",
      "P-JUS-BS         100.000000\n",
      "P-JUS-CKGL        58.353113\n",
      "P-JUS-CKP         71.123209\n",
      "P-MON-CKGL        99.596897\n",
      "P-MON-CKP          9.244156\n",
      "P-MON-SDV-P      100.000000\n",
      "P-PDG             10.336197\n",
      "PT-P             100.000000\n",
      "P-TPT              7.026990\n",
      "QBS              100.000000\n",
      "QGL               67.924246\n",
      "T-JUS-CKP         20.934145\n",
      "T-MON-CKP         69.162512\n",
      "T-PDG             72.826739\n",
      "T-TPT             13.399137\n",
      "class              5.259879\n",
      "state              5.259879\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# print percentage of null values in the cleaned dataframe for each column \n",
    "print('Percentage of null values in the cleaned dataframe')\n",
    "print(df.isnull().sum()/len(df)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "      <th>well</th>\n",
       "      <th>id</th>\n",
       "      <th>ABER-CKGL</th>\n",
       "      <th>ABER-CKP</th>\n",
       "      <th>ESTADO-DHSV</th>\n",
       "      <th>ESTADO-M1</th>\n",
       "      <th>ESTADO-M2</th>\n",
       "      <th>ESTADO-PXO</th>\n",
       "      <th>...</th>\n",
       "      <th>PT-P</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>QBS</th>\n",
       "      <th>QGL</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>T-MON-CKP</th>\n",
       "      <th>T-PDG</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>class</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-12-17 14:27:45</td>\n",
       "      <td>9</td>\n",
       "      <td>WELL-00042</td>\n",
       "      <td>20141217142745</td>\n",
       "      <td>23.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10180070.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.032789</td>\n",
       "      <td>40.20570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.58371</td>\n",
       "      <td>58.95389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-12-17 14:27:46</td>\n",
       "      <td>9</td>\n",
       "      <td>WELL-00042</td>\n",
       "      <td>20141217142745</td>\n",
       "      <td>23.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10180060.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.033681</td>\n",
       "      <td>40.20566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.58370</td>\n",
       "      <td>58.95395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-12-17 14:27:47</td>\n",
       "      <td>9</td>\n",
       "      <td>WELL-00042</td>\n",
       "      <td>20141217142745</td>\n",
       "      <td>23.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10180050.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.034572</td>\n",
       "      <td>40.20562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.58369</td>\n",
       "      <td>58.95401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-12-17 14:27:48</td>\n",
       "      <td>9</td>\n",
       "      <td>WELL-00042</td>\n",
       "      <td>20141217142745</td>\n",
       "      <td>23.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10180040.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.035463</td>\n",
       "      <td>40.20559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.58368</td>\n",
       "      <td>58.95407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-12-17 14:27:49</td>\n",
       "      <td>9</td>\n",
       "      <td>WELL-00042</td>\n",
       "      <td>20141217142745</td>\n",
       "      <td>23.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10180040.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.036354</td>\n",
       "      <td>40.20555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.58368</td>\n",
       "      <td>58.95413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  label        well              id  ABER-CKGL  \\\n",
       "0  2014-12-17 14:27:45      9  WELL-00042  20141217142745       23.0   \n",
       "1  2014-12-17 14:27:46      9  WELL-00042  20141217142745       23.0   \n",
       "2  2014-12-17 14:27:47      9  WELL-00042  20141217142745       23.0   \n",
       "3  2014-12-17 14:27:48      9  WELL-00042  20141217142745       23.0   \n",
       "4  2014-12-17 14:27:49      9  WELL-00042  20141217142745       23.0   \n",
       "\n",
       "   ABER-CKP  ESTADO-DHSV  ESTADO-M1  ESTADO-M2  ESTADO-PXO  ...  PT-P  \\\n",
       "0      38.0          NaN        1.0        1.0         0.0  ...   NaN   \n",
       "1      38.0          NaN        1.0        1.0         0.0  ...   NaN   \n",
       "2      38.0          NaN        1.0        1.0         0.0  ...   NaN   \n",
       "3      38.0          NaN        1.0        1.0         0.0  ...   NaN   \n",
       "4      38.0          NaN        1.0        1.0         0.0  ...   NaN   \n",
       "\n",
       "        P-TPT  QBS       QGL  T-JUS-CKP  T-MON-CKP     T-PDG     T-TPT  class  \\\n",
       "0  10180070.0  NaN  3.032789   40.20570        NaN  74.58371  58.95389    NaN   \n",
       "1  10180060.0  NaN  3.033681   40.20566        NaN  74.58370  58.95395    NaN   \n",
       "2  10180050.0  NaN  3.034572   40.20562        NaN  74.58369  58.95401    NaN   \n",
       "3  10180040.0  NaN  3.035463   40.20559        NaN  74.58368  58.95407    NaN   \n",
       "4  10180040.0  NaN  3.036354   40.20555        NaN  74.58368  58.95413    NaN   \n",
       "\n",
       "   state  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  \n",
       "3    NaN  \n",
       "4    NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename the ids for simulated and handdrawn ids to avoid repetition\n",
    "df['id'] = np.where(\n",
    "    df['well'] == 'SIMULATED',\n",
    "    'SIMULATED - ' + df['id'].astype(str) + \" - \" + df['label'].astype(str),\n",
    "    np.where(\n",
    "        df['well'] == 'DRAWN',\n",
    "        'DRAWN - ' + df['id'].astype(str) + \" - \" + df['label'].astype(str),\n",
    "        df['id']\n",
    "    )\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0s/y0l9zmw16tv5wcmqxk57mrth0000gn/T/ipykernel_39812/3367687249.py:9: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_fill = df.iloc[:, :-2].groupby('id').apply(lambda group: group.fillna(method='ffill').fillna(method='bfill'))\n"
     ]
    }
   ],
   "source": [
    "# Sort the entire DataFrame by 'id' and 'timestamp' first\n",
    "df = df.sort_values(['id', 'timestamp'])\n",
    "\n",
    "# Group by 'id' and apply forward and backward filling within each group except the last 2 columns\n",
    "# Separate the last two columns\n",
    "last_two_cols = df.iloc[:, -2:]\n",
    "\n",
    "# Perform forward and backward fill on all columns except the last two\n",
    "df_fill = df.iloc[:, :-2].groupby('id').apply(lambda group: group.fillna(method='ffill').fillna(method='bfill'))\n",
    "\n",
    "# Concatenate the filled columns with the last two columns\n",
    "df_fill = pd.concat([df_fill.reset_index(drop=True), last_two_cols.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Check for any remaining null values and print instances if needed\n",
    "null_instances = df_fill[df_fill.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of null values in the cleaned dataframe\n",
      "timestamp          0.000000\n",
      "label              0.000000\n",
      "well               0.000000\n",
      "id                 0.000000\n",
      "ABER-CKGL         88.741265\n",
      "ABER-CKP          83.731365\n",
      "ESTADO-DHSV       81.838010\n",
      "ESTADO-M1         76.568290\n",
      "ESTADO-M2         76.522708\n",
      "ESTADO-PXO        76.208673\n",
      "ESTADO-SDV-GL     77.505139\n",
      "ESTADO-SDV-P      68.183531\n",
      "ESTADO-W1         75.211238\n",
      "ESTADO-W2         75.735317\n",
      "ESTADO-XO         75.735317\n",
      "P-ANULAR          66.738525\n",
      "P-JUS-BS         100.000000\n",
      "P-JUS-CKGL        58.290191\n",
      "P-JUS-CKP         71.122121\n",
      "P-MON-CKGL        99.596847\n",
      "P-MON-CKP          9.179966\n",
      "P-MON-SDV-P      100.000000\n",
      "P-PDG              9.590798\n",
      "PT-P             100.000000\n",
      "P-TPT              7.009305\n",
      "QBS              100.000000\n",
      "QGL               67.837530\n",
      "T-JUS-CKP         20.871432\n",
      "T-MON-CKP         69.160266\n",
      "T-PDG             72.120284\n",
      "T-TPT             13.381851\n",
      "class              5.259879\n",
      "state              5.259879\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# print percentage of null values in the cleaned dataframe for each column \n",
    "print('Percentage of null values in the cleaned dataframe')\n",
    "print(df_fill.isnull().sum()/len(df_fill)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_fill' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Drop columns with more than 50% missing values\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_no_nulls \u001b[38;5;241m=\u001b[39m df_fill\u001b[38;5;241m.\u001b[39mdropna(thresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(df_fill) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize a list to store cleaned data\u001b[39;00m\n\u001b[1;32m      5\u001b[0m cleaned_data_list \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_fill' is not defined"
     ]
    }
   ],
   "source": [
    "# Drop columns with more than 50% missing values\n",
    "df_no_nulls = df_fill.dropna(thresh=len(df_fill) * 0.5, axis=1)\n",
    "\n",
    "# Initialize a list to store cleaned data\n",
    "cleaned_data_list = []\n",
    "\n",
    "# Group by 'id' to process each ID at once\n",
    "for id_value, id_data in df_no_nulls.groupby('id'):\n",
    "    # Check if any column is fully null for this ID group\n",
    "    if id_data.iloc[:, :-2].isnull().any(axis=0).any():\n",
    "        if any(id_data[col].isnull().all() for col in id_data.columns[:-2]):\n",
    "            print(f'Dropping id {id_value} due to fully null column(s)')\n",
    "            # Print percentage of null per column for dropped ids\n",
    "            print(id_data.isnull().mean() * 100)\n",
    "            continue  # Skip this id_data if any column is fully null\n",
    "\n",
    "    # Append the cleaned data for the ID\n",
    "    cleaned_data_list.append(id_data)\n",
    "\n",
    "# Concatenate all cleaned data into one DataFrame\n",
    "no_nulls = pd.concat(cleaned_data_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of null values in the cleaned dataframe\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'no_nulls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#get the null values in no_nulls dataframe\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPercentage of null values in the cleaned dataframe\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(no_nulls\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(no_nulls)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'no_nulls' is not defined"
     ]
    }
   ],
   "source": [
    "#get the null values in no_nulls dataframe\n",
    "print('Percentage of null values in the cleaned dataframe')\n",
    "print(no_nulls.isnull().sum()/len(no_nulls)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'no_nulls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# print total ids in the no_nulls dataframe\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal number of unique ids in the cleaned data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mno_nulls[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# print the number of unique ids in original \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal number of unique ids in the original data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'no_nulls' is not defined"
     ]
    }
   ],
   "source": [
    "# print total ids in the no_nulls dataframe\n",
    "print(f'Total number of unique ids in the cleaned data: {no_nulls[\"id\"].nunique()}')\n",
    "\n",
    "# print the number of unique ids in original \n",
    "print(f'Total number of unique ids in the original data: {df[\"id\"].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_class_values(group):\n",
    "    # Define the labels that have transition states\n",
    "    transition_labels = {1, 2, 5, 6, 7, 8, 9}\n",
    "    # Get the label for this group (assumes all rows in a group have the same label)\n",
    "    label_value = group['label'].iloc[0]\n",
    "\n",
    "    # Initialize starting NaNs as 0 (normal operation) until the first non-null value\n",
    "    first_non_null_index = group['class'].first_valid_index()\n",
    "    if first_non_null_index is not None:\n",
    "        # Fill initial NaNs with 0 up to the first non-null value\n",
    "        group.loc[:first_non_null_index, 'class'] = group.loc[:first_non_null_index, 'class'].fillna(0)\n",
    "    \n",
    "    # Now, iterate through the rows to apply the transition and event logic\n",
    "    for idx in group.index:\n",
    "        # If class is NaN and we're in the transition state (state=1) and label allows transitions\n",
    "        if pd.isna(group.loc[idx, 'class']):\n",
    "            if group.loc[idx, 'state'] == 1 and label_value in transition_labels:\n",
    "                group.loc[idx, 'class'] = 100 + label_value  # Start transition state\n",
    "            else:\n",
    "                # If it's not a transition state, fill with label (event state)\n",
    "                group.loc[idx, 'class'] = label_value\n",
    "\n",
    "    return group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get list of ids that have null class values\n",
    "ids_with_null_class = no_nulls[no_nulls['class'].isnull()]['id'].unique()\n",
    "\n",
    "len(ids_with_null_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Pick a random value from 0 to len of list\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ran \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(ids_with_null_class))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Get the id from the list\u001b[39;00m\n\u001b[1;32m      5\u001b[0m id_value \u001b[38;5;241m=\u001b[39m ids_with_null_class[ran]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Pick a random value from 0 to len of list\n",
    "ran = np.random.randint(0, len(ids_with_null_class))\n",
    "\n",
    "# Get the id from the list\n",
    "id_value = ids_with_null_class[ran]\n",
    "\n",
    "# Get the data for the id\n",
    "id_data = no_nulls[no_nulls['id'] == id_value].copy()\n",
    "\n",
    "id_data_copy = id_data.copy()\n",
    "\n",
    "# Fill NaNs in 'class' with 10 for demonstration\n",
    "id_data['class'] = id_data['class'].fillna(10)\n",
    "\n",
    "# Reduce data points for plotting if there are too many\n",
    "if len(id_data) > 1000:  # Arbitrary threshold for downsampling\n",
    "    id_data = id_data.iloc[::10]  # Take every 10th row\n",
    "\n",
    "print(f'ID: {id_value}')\n",
    "print(id_data['label'].value_counts())\n",
    "\n",
    "# Plot class changes over time compared with the top correlated column\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(id_data['timestamp'], id_data['class'], label='class', color='blue', marker='o')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.title(f'Class Changes Over Time for ID {id_value} Compared with timestamp')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()  # Adjust layout for better fit\n",
    "plt.show()\n",
    "\n",
    "# Apply the function to update the class values\n",
    "id_data_copy = update_class_values(id_data_copy)\n",
    "\n",
    "print(f'ID: {id_value}')\n",
    "print(id_data['label'].value_counts())\n",
    "\n",
    "# Plot class changes over time compared with the top correlated column\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(id_data_copy['timestamp'], id_data_copy['class'], label='class', color='blue', marker='o')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.title(f'Class Changes Over Time for ID {id_value} Compared with timestamp')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()  # Adjust layout for better fit\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of null values in the cleaned dataframe\n",
      "timestamp    0.000000\n",
      "label        0.000000\n",
      "well         0.000000\n",
      "id           0.000000\n",
      "P-MON-CKP    0.000000\n",
      "P-PDG        0.000000\n",
      "P-TPT        0.000000\n",
      "T-JUS-CKP    0.000000\n",
      "T-TPT        0.000000\n",
      "class        0.000000\n",
      "state        3.039702\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# apply the function to update the class values for all ids\n",
    "no_nulls = no_nulls.groupby('id').apply(update_class_values)\n",
    "\n",
    "# print percentage of null values in the cleaned dataframe\n",
    "print('Percentage of null values in the cleaned dataframe')\n",
    "print(no_nulls.isnull().sum()/len(no_nulls)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 53057829 entries, (20131004225400, 0) to ('SIMULATED - 99 - 9', 53057828)\n",
      "Data columns (total 10 columns):\n",
      " #   Column     Dtype         \n",
      "---  ------     -----         \n",
      " 0   timestamp  datetime64[ns]\n",
      " 1   label      int64         \n",
      " 2   well       object        \n",
      " 3   id         object        \n",
      " 4   P-MON-CKP  float64       \n",
      " 5   P-PDG      float64       \n",
      " 6   P-TPT      float64       \n",
      " 7   T-JUS-CKP  float64       \n",
      " 8   T-TPT      float64       \n",
      " 9   class      float64       \n",
      "dtypes: datetime64[ns](1), float64(6), int64(1), object(2)\n",
      "memory usage: 6.7+ GB\n"
     ]
    }
   ],
   "source": [
    "#drop state column\n",
    "no_nulls = no_nulls.drop('state', axis=1)\n",
    "\n",
    "# change timestamp as datetime\n",
    "no_nulls['timestamp'] = pd.to_datetime(no_nulls['timestamp'])\n",
    "\n",
    "#change id as str\n",
    "no_nulls['id'] = no_nulls['id'].astype(str)\n",
    "\n",
    "no_nulls.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save parquet file\n",
    "no_nulls.to_parquet('Data/cleaned_data.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
